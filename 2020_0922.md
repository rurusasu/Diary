# 修論の文章作成

## ニューラルネットワーク

人間の脳は、神経細胞（ニューロン）とそれを支える構造部材としての役割を持つグリアによって構成される。1943 年、神経生理学者の W. S. McCulloch と数学者の W. Pitts は、当時一般に認められていたニューロンの特徴と 5 つの仮定から、ニューロンを単純な論理ゲートとしてモデル化した(MCP ニューロン) [1] [2]。このモデルは、ニューロンにおける「樹上突起に到達した信号は細胞体内に蓄積し、ある閾値を超えると出力信号が生成され、軸索によって次のニューロンに伝達される」という機能を表現している。1957 年、F. Rosenblatt は MCP ニューロンモデルに基づいて設計された人工ニューロン(パーセプトロン)の学習規則に関する概念を発表した [3]。これは、2 値分類問題においてパーセプトロンは有限回の反復で
ここでの 2 値分類問題とは次のようなものである。

N 個の教師例
$\{(x_i,y)^{(j)}\}, x_i∈R^n, y∈{-1,1}, i=1,…,M, j=1,…N$
が与えられたときに 2 つの分類 $y=-1,1$ を判別する基準(決定関数$\phi$)を求める問題。

パーセプトロンは、入力値
$\bf{x}=[x_1,…,x_M ]^T$
とそれに対応する重みベクトル
$\bf{w}=[w_1,…,w_M ]^T$
の線形結合
$z=\bf{w}^T \bf{x}$
を引数として受け取る。そして、サンプル
$\bf{x}^{(j)}$
における
$z^{(j)}$
がある閾値
$\theta$
以上の場合は 1 を、小さい場合は-1 を出力として
$x^{(j)}$
のクラスを予測する。このため、パーセプトロンの決定関数は、単位ステップ関数である。

$$
\phi(z) = \left\{
    \begin{array}{||}
    1 & (z \geq \theta) \\
    -1 & (z \lt \theta)
    \end{array}
    \right.
$$

話を単純にするために、$w_0 = -\theta$, $x_0=1$ とおくことで、パーセプトロンの決定関数を改めて次のように定義する。

$$
\phi(z) = \left\{
    \begin{array}{||}
    1 & (z \geq 0) \\
    -1 & (z \lt 0)
    \end{array}
    \right.
$$

$$
z,w,x \in R^{(n+1)}
$$

ここで、$w_0=-\theta$ はバイアスと呼ばれる。
パーセプトロンの学習規則は上記の数式を用いると、次の手順にまとめることができる。
重み $w$ を $0$ または値の小さな乱数で初期化する。
訓練サンプル $x^{(j)}$ごとに次の手順を実行する。
出力値 $\hat{y}=\phi(z)$を計算する。
$y^{(j)}≠y^{(j)}$の場合、以下の式で重みを更新する。

$$
w_i:=w_i+\eta \left(y^{(j)}-y^{(j)}\right)x_i^{(j)}
$$

ここで、$\eta$ は学習率と呼ばれる $0 \lt η \leq 1$ の定数である。
