# Kolmogorov写像ニューラルネットワーク存在定理
任意の連続関数 $f : [0, 1]^n \rightarrow R^m, f({\bf x}) = {\bf y}$ が与えられたとき, $f$ は, 第一層(すなわち $x$ 入力層)に $n$ 個のファインアウト処理要素, 中間層に $(2n+1)$ 個の処理要素, そして最上層(すなわち $y$ 出力層) に $m$ 個の処理要素を持つ3層フィードフォワード・ニューラルネットワークにより正確に実現できる.

この定理に述べられたように, **Kolmogorov写像ネットワーク**(Kolmogorov mapping network) は3層の処理要素からなる. 下層の処理要素は単に入力ベクトル要素を第二相の処理要素に分配するファインアウト・ユニットである. 中間層または**隠れ**(hidden)層の処理要素が以下の伝達関数を実現する.
$$
Z_k = \sum_{j=1}^n \lambda^k \psi (x_j + k \epsilon) + k
$$

ここで, 実数定数 $\lambda$ と連続な実数値単調増加関数 $\psi$ は, $f$ に独立である(それは $n$ に依存するが).
定数 $\epsilon$ は $0 < \epsilon \leq \delta$ を満たす有理数である. ただし, $\delta$ は任意に選ばれた正定数とする. 
$m$ 個の最上部処理要素(出力ユニット)は以下の伝達関数を持つ.
$$
y_i = \sum_{k=1}^{2n+1} g_i(z_k)
$$
ここで関数 $g_i$, $i=1, 2, \cdots, n$ は連続な実数値関数である( $g_i$ は $f$ と $\epsilon$ に依存する).