---
marp: true
---

<!--
theme: default
size: 4:3
page_number: true
paginate: true
header: "2020年○月○日"
style: |

  section { font-size: 20px;}

  header {
    width: 100%;
    font-size: 20px;
    color: black;
    padding: 1px;
    top: 50px;
  }

  footer {
    width: 100%;
    font-size: 20px;
    color: black;
    text-align: right;
    padding: 15px;
  }

  h1 {
    font-size: 40;
    color: navy;
  }

  h2 {
    font-size: 35;
    color: navy;
  }

  h3 {
    font-size: 30;
    color: navy;
  }

  pre, code{
    font-size: 18px;
  }
-->

## 一般的な画像

一般的なカメラで撮影された写真は、3 次元空間を切り取って 2 次元に映し出すため、3 次元空間上に合った距離などの情報が失われる。よって、1 枚の写真からでは写っている object の 3 次元空間上の位置などを把握することができない。

## エピポーラ

<div align="center">
<img src="https://raw.githubusercontent.com/rurusasu/Diary/master/%E7%94%BB%E5%83%8F/1021/Epipolar_geometry.png", width="55%">
</div>

図は[wikipedia](https://en.wikipedia.org/wiki/Epipolar_geometry)より引用、文章は[Qiita](https://qiita.com/YosukeHoshi/items/08bb7f3d293565f29ae0)より引用

---

上の図は、物体 $X$ を Left view と Right view の 2 つの視点にあるカメラで撮影しているところを表している。ここで、点 $O_L$ と点 $O_R$ はそれぞれのカメラの中心を示している。また、点 $X$、点 $O_L$、点 $O_R$ の 3 点を結んでできる面を **エピポーラ面** という(図中の緑の領域)。

今、点 $O_L$ から点 $X$ にある物体を撮影した写真を見ているとする。
このとき、写真に写った物体 $X$ は直線 $O_L, X_L$ の延長線上に存在することはわかるが、その距離はわからない。

そこで、点 $O_R$ から点 $X$ にある物体を撮影した写真を使うことにする。
この写真では、直線 $O_L, X_L$ の延長線上に存在しているはずの物体 $X$ が、赤線上に見つけられる。この赤線を **エピポーラ線** と呼ぶ。

反対に、Right view においてエピポーラ線がわかれば、left view における 点 $X_L$ の位置を見つけることができる。これを **エピポーラ拘束** という。

---

また、Left view と Right view の位置関係は **エピポール** によって把握することができる。エピポールとは、図における点 $O_L$ と点 $O_R$ とを結んだ直線上に存在する点 $e_L$ と $e_R$ のことである。エピポールは次の特徴を持つ。

- 左右それぞれの視点の中心を結ぶ直線とそれぞれの画像平面の交点に存在する。
- 全てのエピポーラ線が通る点である(そのため、複数のエピポーラ線の交点を探すことでも見つけることができる)。

---

# エッジ点

画像の明度変化率が局所的に最大である場所(位置)のこと。

## 1 次元的な例

ある関数の「変化率」は、数学的に「1 次微分」で記述できる。そのため、エッジ点は画像の明度関数 $I(x)$ の一次微分が極値を持つ場所にあるということができる。すなわち、

$$
x_0 = \max_{x\in N} \left[ \frac{dI(x)}{dx} \right]
$$

ここで、$N$ は極値近傍領域のことであり、$x_0$ はエッジ点を表す。

---

## 2 次元の場合

画像の明度は 2個の独立変数 $(x, y)$ についての関数である。
従って、微分を計算するには、その方向を指定しなければならない。



---

# Harris コーナー検出

初期の Computer vision におけるコーナー検出の試みとして **Chris Harris** と **Mike Stephens** が **A Combined Corner and Edge Detector** という論文で発表した **Harris コーナー** と呼ばれる方法がある。

## Harris コーナー

基本的には全方向に対して画素位置 $(u, v)$ の移動量に対する画素値の違いを見つける。

$$
E(u, v) = \sum_{x, y} w(x, y) \left[ I(x+u, y+v) - I(x, y) \right]^2
$$

ここで、$w(x, y)$ は窓関数で矩形窓か画素に対して重み付けをするガウシアン窓を使用する。

コーナー検出のためにこの関数
